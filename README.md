# Reinforcement learning of model transformation (RL4MT)

## Installation 

(1) Create virtual environment 

--> using Anaconda (Anaconda prompt)
```
conda create --name Transformer python=3.12
conda activate Transformer
```

--> using pyton venv (cmd)
```
python -m venv Transformer/.venv
cd Transformer
.venv\Scripts\activate.bat
```

(2) Install the dependent libraries
```
pip install -r requirements.txt
```

## Settings 

The configuration file can be called via  ```./config/settings.ini```

```settings.ini``` file defines the following hyperparameters of the learning algorithm :

| Hyperparameters    | Default value | Comments |
|--------------------|:-------------:|:---------|
| ```POLICY```       | q_learning    | Policy *deep_q_learning* is also available |
| ```EPISODE```      | 1000          | Number of episodes until perfect agent training |
| ```EPSILON```      | 1             | The epsilon score starts at 1 and decreases linearly to 0 as learning progresses. The closer epsilon gets to 0, the more the agent reuses the knowledge learned |
| ```LEARNING_RATE```| 0.1           | - |
| ```GAMMA_FACTOR``` | 0.9           | The closer gamma is to 1, the greater the agent's interest in possible |future rewards.

## Input datas
Input data format: *.ecore* for metamodels and *.xmi* for models

The dataset files are organized as follows :
```
Transformer
├── datasets
│   ├── Class2Relational
│   │   ├── Metamodels
│   │   │   ├── Class.ecore
|   |   |   ├── Relational.ecore
│   │   ├── Models
│   │   │   ├── training
|   |   |   |   ├── Book_class_diagram.xmi
|   |   |   |   ├── Book_relational_diagram.xmi
│   │   │   ├── validation
|   |   |   |   ├── Computer_class_diagram.xmi
│   │   ├── Transformation
|   |   |   |   ├── model_transformation.pkl
```
To summarize, you can add your own model transformation by following the steps below:

(1) Create a folder for the transformation ```./datasets/<name_source_metamodel>2<name_target_metamodel>``` (where *name_source_metamodel* and *name_target_metamodel* correspond to the exact names of the source and target metamodels, as shown in the example above). 

(2) Create a ```Metamodels``` subfolder containing the *.ecore* files of your source and target metamodels for which you want to learn the model transformation  ```./datasets/<name_source_metamodel>2<name_target_metamodel>/Metamodels```.

(3) Create a ```Models``` subfolder containing the ```training``` and ```validation``` subfolders where you will store your models in *.xmi* format. ```./datasets/<name_source_metamodel>2<name_target_metamodel>/Models```.

* The *traning* subfolder must contain at least one source model and the corresponding target model.

* The *validation* subfolder contains the source models for which you want to validate the correct functioning of the previously learned transformation model.

(4) The ```Transformation``` folder contains the ```model_transformation.pkl``` object, which encapsulates the transformation rules learned by the agent after the training phase. This means that the folder is empty before the training takes place.


## Ouput datas

The results achieved during the training and prediction phases are stored in the following folder architecture:
```
Transformer
├── experiments
│   ├── prediction
│   │   ├── <date_of_day>
│   │   │   ├── <hour_of_day>
│   │   │   |   ├── <output_target_model>.xmi
│   │   │   |   ├── log.txt
│   ├── training
│   │   ├── <date_of_day>
│   │   │   ├── <hour_of_day>
│   │   │   |   ├── model_transformation.pkl
│   │   │   |   ├── log_flattened_classes.txt
│   │   │   |   ├── transitions.txt
```
Whether in the ```training``` folder or the ```prediction``` folder, your experiments are archived in folders depending on the current date and execution time of the algorithm, as shown in the example above.

* The ```training``` folder is generated once training has started. It contains the following elements:

| Files                          |  Comments    |
|--------------------------------|:-------------|
| ```model_transformation.pkl``` | Python object containing flattened classes of source and target models as well as transformation rules learned by the agent |
| ```log_flattened_classes.txt```| Contains flattened classes of source and target models generated by the agent |
| ```log_transitions.txt```      | Contains the transitions that the agent goes through during the training phase |
| ```log_actions_list```         | Contains the list of transformation rules that the agent tested during the training phase |

* The ```prediction``` folder is generated once the transformation of new instance model has started. It contains the following elements:

| Files                          |  Comments    |
|--------------------------------|:-------------|
| ```<output_target_model>.xmi```| Where *output_target_model* correspond to the name of the new target model created |
| ```log.txt```                  | Corresponds to the log file created during the design of the target model |

## Start training

The following command line starts the training algorithm. The training is carried out for the *Book* class2relational transformation.

```
cd Transformer
python main.py -sm Book_class_diagram.xmi -smm Class.ecore -tm Book_relational_diagram.xmi -tmm Relational.ecore -l
```

## Start prediction

The following command line starts the prediction algorithm. The prediction is carried out for the *Computer* class2relational transformation.

```
cd Transformer
python main.py -sm Book_class_diagram.xmi -smm Class.ecore -tm Book_relational_diagram.xmi -tmm Relational.ecore -l
```